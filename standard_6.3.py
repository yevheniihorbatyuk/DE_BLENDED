import datetime
import uuid
import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType, StringType

# ğŸ”§ ĞĞ°Ğ»Ğ°ÑˆÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ´Ğ»Ñ Ñ€Ğ¾Ğ±Ğ¾Ñ‚Ğ¸ Ğ· Kafka Ñ‡ĞµÑ€ĞµĞ· PySpark
os.environ["PYSPARK_SUBMIT_ARGS"] = (
    "--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1 pyspark-shell"
)

# ğŸ”‘ ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ Kafka
KAFKA_BOOTSTRAP = "77.81.230.104:9092"
KAFKA_TOPIC_INPUT = "building_sensors_greenmoon"
KAFKA_TOPIC_OUTPUT = "alerts_stream"
KAFKA_USERNAME = "admin"
KAFKA_PASSWORD = "VawEzo1ikLtrA8Ug8THa"

# ğŸš€ Ğ†Ğ½Ñ–Ñ†Ñ–Ğ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Spark Session
spark = (
    SparkSession.builder.appName("KafkaStreaming")
    .master("local[*]")  # Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ğ½Ñ Ğ²ÑÑ–Ñ… ÑĞ´ĞµÑ€ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ĞºĞ¾Ğ¼Ğ¿'ÑÑ‚ĞµÑ€Ğ°
    .config("spark.sql.debug.maxToStringFields", "200")
    .config("spark.sql.shuffle.partitions", "4")  # ĞĞ¿Ñ‚Ğ¸Ğ¼Ñ–Ğ·Ğ°Ñ†Ñ–Ñ Ğ¿Ğ°Ñ€Ñ‚Ğ¸Ñ†Ñ–Ğ¹
    .config("spark.streaming.backpressure.enabled", "true")  # ĞĞ²Ñ‚Ğ¾-Ñ€ĞµĞ³ÑƒĞ»ÑĞ²Ğ°Ğ½Ğ½Ñ Ğ½Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ
    .config("spark.sql.session.timeZone", "UTC")  # ĞšĞ¾Ñ€ĞµĞºÑ†Ñ–Ñ Ñ‡Ğ°ÑĞ¾Ğ²Ğ¸Ñ… Ğ·Ğ¾Ğ½
    .getOrCreate()
)

# ğŸ“ Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ CSV-Ñ„Ğ°Ğ¹Ğ»Ñƒ Ğ· ÑƒĞ¼Ğ¾Ğ²Ğ°Ğ¼Ğ¸ Ğ°Ğ»ĞµÑ€Ñ‚Ñ–Ğ²
alerts_df = spark.read.option("header", True).csv("./data/alerts_conditions.csv")

# ğŸ—ï¸ Ğ¡Ñ…ĞµĞ¼Ğ° JSON-Ğ¿Ğ¾Ğ²Ñ–Ğ´Ğ¾Ğ¼Ğ»ĞµĞ½ÑŒ Kafka
json_schema = StructType([
    StructField("sensor_id", IntegerType(), True),
    StructField("timestamp", StringType(), True),
    StructField("temperature", DoubleType(), True),
    StructField("humidity", DoubleType(), True),
])

# ğŸ”Œ Ğ§Ğ¸Ñ‚Ğ°Ğ½Ğ½Ñ Ğ¿Ğ¾Ñ‚Ğ¾ĞºÑƒ Ğ· Kafka
raw_stream_df = (
    spark.readStream.format("kafka")
    .option("kafka.bootstrap.servers", KAFKA_BOOTSTRAP)
    .option("kafka.security.protocol", "SASL_PLAINTEXT")
    .option("kafka.sasl.mechanism", "PLAIN")
    .option(
        "kafka.sasl.jaas.config",
        f'org.apache.kafka.common.security.plain.PlainLoginModule required username="{KAFKA_USERNAME}" password="{KAFKA_PASSWORD}";',
    )
    .option("subscribe", KAFKA_TOPIC_INPUT)
    .option("startingOffsets", "latest")
    .option("maxOffsetsPerTrigger", "500")  # Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼Ñ–Ğ¶ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ñ–ÑÑ‚Ñ Ñ– Ğ·Ğ°Ñ‚Ñ€Ğ¸Ğ¼ĞºĞ¾Ñ
    .load()
)

# ğŸ“¡ Ğ”ĞµĞºĞ¾Ğ´ÑƒĞ²Ğ°Ğ½Ğ½Ñ JSON Ñ–Ğ· Kafka
sensor_data_df = (
    raw_stream_df.selectExpr("CAST(value AS STRING) AS json_string")
    .withColumn("data", from_json(col("json_string"), json_schema))
    .select("data.*")
    .withColumn("timestamp", to_timestamp("timestamp", "yyyy-MM-dd HH:mm:ss"))  # Ğ§Ğ°Ñ Ñƒ ĞºĞ¾Ñ€ĞµĞºÑ‚Ğ½Ğ¾Ğ¼Ñƒ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ–
)

# ğŸ” Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ Ñ‡Ğ°ÑĞ¾Ğ²Ğ¸Ñ… Ğ²Ñ–ĞºĞ¾Ğ½
windowed_df = (
    sensor_data_df.withWatermark("timestamp", "10 seconds")  # Ğ’Ñ€Ğ°Ñ…ÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ·Ğ°Ğ¿Ñ–Ğ·Ğ½Ñ–Ğ»Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ¸Ñ…
    .groupBy(window("timestamp", "1 minute", "30 seconds"))  # Ğ’Ñ–ĞºĞ¾Ğ½Ğ½Ğ° Ğ°Ğ³Ñ€ĞµĞ³Ğ°Ñ†Ñ–Ñ
    .agg(
        avg("temperature").alias("avg_temp"),
        avg("humidity").alias("avg_humidity"),
    )
)

# ğŸ›‘ Ğ¤Ñ–Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ñ–Ñ Ğ°Ğ»ĞµÑ€Ñ‚Ñ–Ğ² (Ğ±ĞµĞ· `crossJoin`)
alerts_filtered = (
    windowed_df.join(
        alerts_df,
        (col("avg_temp") > col("temperature_min"))
        & (col("avg_temp") < col("temperature_max"))
        | (col("avg_humidity") > col("humidity_min"))
        & (col("avg_humidity") < col("humidity_max")),
        "inner",
    )
    .withColumn("alert_id", expr("uuid()"))
    .withColumn("alert_time", current_timestamp())
    .select(
        col("alert_id").alias("key"),
        to_json(
            struct(
                col("window"),
                col("avg_temp"),
                col("avg_humidity"),
                col("code"),
                col("message"),
                col("alert_time"),
            )
        ).alias("value"),
    )
)

# ğŸ–¥ï¸ Ğ’Ğ¸Ğ²ĞµĞ´ĞµĞ½Ğ½Ñ Ğ°Ğ»ĞµÑ€Ñ‚Ñ–Ğ² Ñƒ ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ (Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ Ğ´Ğ»Ñ Ğ´ĞµĞ±Ğ°Ğ³Ñƒ)
console_output = (
    alerts_filtered.writeStream.outputMode("append")
    .format("console")
    .option("truncate", "false")
    .option("numRows", 10)
    .trigger(processingTime="10 seconds")
    .start()
)

# ğŸ“¡ Ğ—Ğ°Ğ¿Ğ¸Ñ Ğ°Ğ»ĞµÑ€Ñ‚Ñ–Ğ² Ğ½Ğ°Ğ·Ğ°Ğ´ Ñƒ Kafka
kafka_output = (
    alerts_filtered.writeStream.outputMode("append")
    .format("kafka")
    .option("kafka.bootstrap.servers", KAFKA_BOOTSTRAP)
    .option("kafka.security.protocol", "SASL_PLAINTEXT")
    .option("kafka.sasl.mechanism", "PLAIN")
    .option(
        "kafka.sasl.jaas.config",
        f'org.apache.kafka.common.security.plain.PlainLoginModule required username="{KAFKA_USERNAME}" password="{KAFKA_PASSWORD}";',
    )
    .option("topic", KAFKA_TOPIC_OUTPUT)
    .trigger(processingTime="10 seconds")
    .start()
)

# ğŸ ĞÑ‡Ñ–ĞºÑƒĞ²Ğ°Ğ½Ğ½Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ ÑÑ‚Ñ€Ñ–Ğ¼Ñƒ
console_output.awaitTermination()
kafka_output.awaitTermination()
